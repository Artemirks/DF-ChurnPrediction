{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kFujS3WHFbbd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8bQYmQ3dFjfb"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(filepath): #подготовка данных для последующего обучения\n",
        "  balanced_data = pd.read_parquet(filepath)\n",
        "  X = balanced_data.drop(['target'], axis=1)\n",
        "  y = balanced_data['target']\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "  scaler = joblib.load('scaler_80_20_new.joblib')\n",
        "  pca = joblib.load('pca_80_20_new.joblib')\n",
        "\n",
        "  X_train_scaled = scaler.transform(X_train)\n",
        "  X_train_pca = pca.transform(X_train_scaled)\n",
        "\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "  X_test_pca = pca.transform(X_test_scaled)\n",
        "  return X_train_pca, y_train, X_test_pca, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u684sLcQFywa"
      },
      "outputs": [],
      "source": [
        "def get_metrics(y_test, y_pred): #подсчет метрик\n",
        "  roc_auc = roc_auc_score(y_test, y_pred)\n",
        "  f1 = f1_score(y_test, y_pred)\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  precision = precision_score(y_test, y_pred)\n",
        "\n",
        "  print(f\"ROC AUC: {roc_auc}\")\n",
        "  print(f\"F1 Score: {f1}\")\n",
        "  print(f\"Recall: {recall}\")\n",
        "  print(f\"Precision: {precision}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "NC7R7gPRF7yd"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_test, y_test = prepare_dataset('balanced_data_80_20_new.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2Lt87zOiZvD",
        "outputId": "b3992627-3f3d-49fa-99a9-870ff2613abf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64879, 100)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP8LwirsGUpn",
        "outputId": "cb30ccfe-b288-4b3a-81f0-f84188c11fd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1622/1622 [==============================] - 5s 3ms/step - loss: 0.7948 - accuracy: 0.7958 - val_loss: 0.4868 - val_accuracy: 0.7955\n",
            "Epoch 2/100\n",
            "1622/1622 [==============================] - 6s 4ms/step - loss: 0.4837 - accuracy: 0.8031 - val_loss: 0.4838 - val_accuracy: 0.7951\n",
            "Epoch 3/100\n",
            "1622/1622 [==============================] - 5s 3ms/step - loss: 0.4800 - accuracy: 0.8028 - val_loss: 0.4800 - val_accuracy: 0.7953\n",
            "Epoch 4/100\n",
            "1622/1622 [==============================] - 5s 3ms/step - loss: 0.4780 - accuracy: 0.8027 - val_loss: 0.4795 - val_accuracy: 0.7950\n",
            "Epoch 5/100\n",
            "1622/1622 [==============================] - 6s 4ms/step - loss: 0.4758 - accuracy: 0.8027 - val_loss: 0.4798 - val_accuracy: 0.7942\n",
            "Epoch 6/100\n",
            "1622/1622 [==============================] - 6s 4ms/step - loss: 0.4746 - accuracy: 0.8033 - val_loss: 0.4763 - val_accuracy: 0.7972\n",
            "Epoch 7/100\n",
            "1622/1622 [==============================] - 5s 3ms/step - loss: 0.4737 - accuracy: 0.8030 - val_loss: 0.4772 - val_accuracy: 0.7953\n",
            "Epoch 8/100\n",
            "1622/1622 [==============================] - 5s 3ms/step - loss: 0.4733 - accuracy: 0.8031 - val_loss: 0.4774 - val_accuracy: 0.7946\n",
            "Epoch 9/100\n",
            "1622/1622 [==============================] - 5s 3ms/step - loss: 0.4720 - accuracy: 0.8035 - val_loss: 0.4785 - val_accuracy: 0.7949\n",
            "Epoch 10/100\n",
            "1622/1622 [==============================] - 6s 4ms/step - loss: 0.4716 - accuracy: 0.8033 - val_loss: 0.4752 - val_accuracy: 0.7965\n",
            "Epoch 11/100\n",
            "1622/1622 [==============================] - 5s 3ms/step - loss: 0.4708 - accuracy: 0.8028 - val_loss: 0.4744 - val_accuracy: 0.7965\n",
            "Epoch 12/100\n",
            "1622/1622 [==============================] - 5s 3ms/step - loss: 0.4700 - accuracy: 0.8037 - val_loss: 0.4762 - val_accuracy: 0.7949\n",
            "Epoch 13/100\n",
            "1622/1622 [==============================] - 6s 4ms/step - loss: 0.4703 - accuracy: 0.8030 - val_loss: 0.4756 - val_accuracy: 0.7954\n",
            "Epoch 14/100\n",
            "1622/1622 [==============================] - 4s 3ms/step - loss: 0.4702 - accuracy: 0.8029 - val_loss: 0.4756 - val_accuracy: 0.7947\n",
            "Epoch 15/100\n",
            "1622/1622 [==============================] - 5s 3ms/step - loss: 0.4702 - accuracy: 0.8026 - val_loss: 0.4771 - val_accuracy: 0.7942\n",
            "Epoch 16/100\n",
            "1622/1622 [==============================] - 5s 3ms/step - loss: 0.4692 - accuracy: 0.8029 - val_loss: 0.4747 - val_accuracy: 0.7953\n",
            "Epoch 17/100\n",
            "1622/1622 [==============================] - 5s 3ms/step - loss: 0.4692 - accuracy: 0.8032 - val_loss: 0.4743 - val_accuracy: 0.7949\n",
            "Epoch 18/100\n",
            "1622/1622 [==============================] - 6s 4ms/step - loss: 0.4696 - accuracy: 0.8040 - val_loss: 0.4730 - val_accuracy: 0.7970\n",
            "Epoch 19/100\n",
            "1622/1622 [==============================] - 5s 3ms/step - loss: 0.4689 - accuracy: 0.8034 - val_loss: 0.4756 - val_accuracy: 0.7945\n",
            "Epoch 20/100\n",
            "1622/1622 [==============================] - 4s 3ms/step - loss: 0.4693 - accuracy: 0.8025 - val_loss: 0.4731 - val_accuracy: 0.7955\n",
            "Epoch 21/100\n",
            "1622/1622 [==============================] - 6s 4ms/step - loss: 0.4682 - accuracy: 0.8031 - val_loss: 0.4800 - val_accuracy: 0.7950\n",
            "Epoch 22/100\n",
            "1622/1622 [==============================] - 5s 3ms/step - loss: 0.4693 - accuracy: 0.8026 - val_loss: 0.4737 - val_accuracy: 0.7972\n",
            "Epoch 23/100\n",
            "1622/1622 [==============================] - 4s 3ms/step - loss: 0.4699 - accuracy: 0.8035 - val_loss: 0.4725 - val_accuracy: 0.7957\n",
            "Epoch 24/100\n",
            "1622/1622 [==============================] - 6s 3ms/step - loss: 0.4684 - accuracy: 0.8037 - val_loss: 0.4728 - val_accuracy: 0.7954\n",
            "Epoch 25/100\n",
            "1622/1622 [==============================] - 4s 3ms/step - loss: 0.4687 - accuracy: 0.8034 - val_loss: 0.4750 - val_accuracy: 0.7956\n",
            "Epoch 26/100\n",
            "1622/1622 [==============================] - 5s 3ms/step - loss: 0.4683 - accuracy: 0.8037 - val_loss: 0.4718 - val_accuracy: 0.7959\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "869/869 [==============================] - 2s 2ms/step\n",
            "ROC AUC: 0.5138049784236572\n",
            "F1 Score: 0.06086510514617883\n",
            "Recall: 0.03192825112107623\n",
            "Precision: 0.6496350364963503\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Создание и обучение нейронной сети\n",
        "model = Sequential()\n",
        "model.add(Dense(units=128, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "model.add(Dense(units=64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Сохранение модели\n",
        "model.save('neuron_model_80_20_new.h5')\n",
        "\n",
        "# Загрузка сохраненной модели\n",
        "loaded_model = tf.keras.models.load_model('neuron_model_80_20_new.h5')\n",
        "\n",
        "# Предсказание с загруженной моделью\n",
        "y_pred_loaded = loaded_model.predict(X_test)\n",
        "y_pred_binary = (y_pred_loaded > 0.5).astype(int)\n",
        "get_metrics(y_test, y_pred_binary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgdX4HZyGZjE",
        "outputId": "49b488e6-7453-44f6-cfc2-c21617535153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "869/869 [==============================] - 2s 2ms/step\n",
            "Best F1 Score: 0.6516305050536428 at threshold 0.2\n",
            "ROC AUC: 0.6516305050536428\n",
            "F1 Score: 0.4305283757338551\n",
            "Recall: 0.611659192825112\n",
            "Precision: 0.33216442626144554\n"
          ]
        }
      ],
      "source": [
        "y_pred_loaded = loaded_model.predict(X_test)\n",
        "best_threshold = 0.5\n",
        "best_f1_score = 0.0\n",
        "\n",
        "for threshold in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
        "    y_pred_binary = (y_pred_loaded > threshold).astype(int)\n",
        "    f1 = roc_auc_score(y_test, y_pred_binary)\n",
        "    if f1 > best_f1_score:\n",
        "        best_f1_score = f1\n",
        "        best_threshold = threshold\n",
        "\n",
        "print(f\"Best F1 Score: {best_f1_score} at threshold {best_threshold}\")\n",
        "y_pred_binary = (y_pred_loaded > best_threshold).astype(int)\n",
        "get_metrics(y_test, y_pred_binary)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
